# Proyecto: Generaci√≥n de datos sint√©ticos para modelos de predicci√≥n de *bank default analysis*

---

## üîπ FASE 1 ‚Äî Limpieza y preparaci√≥n del dataset original

**Objetivos:**

- Asegurar calidad del dataset real antes de usarlo como base del generador.

**Acciones:**

- Cargar y explorar el dataset (valores nulos, *outliers*, cardinalidad).
- Normalizar tipos de variables (convertir categ√≥ricas, binarizar si es necesario).
- Analizar balance de clases de la variable objetivo (moroso).
- Guardar versi√≥n limpia y documentada del dataset.

**Herramientas:**

- `pandas`, `seaborn`, `matplotlib`, `sklearn.preprocessing`

---

## üîπ FASE 2 ‚Äî Generaci√≥n de datos sint√©ticos

**Objetivos:**

- Entrenar modelos generativos tabulares sobre el dataset limpio.
- Generar un dataset sint√©tico equivalente.

**Modelos recomendados:**

- **CTGAN** ‚Üí Muy s√≥lido para mezcla de variables categ√≥ricas y num√©ricas.
- **TVAE** ‚Üí *Autoencoder* variacional adaptado a tablas.
- **TabDDPM** ‚Üí Difusor de √∫ltima generaci√≥n, ideal para mayor fidelidad.
- *(Opcional)* **GaussianCopula** ‚Üí Modelo estad√≠stico base para comparaci√≥n.

**Acciones:**

- Crear script modular para entrenar cada generador.
- Configurar entrenamiento y *sampling* con cada modelo.
- Generar un dataset sint√©tico de tama√±o igual al original.
- Guardar los datasets sint√©ticos con trazabilidad del modelo usado.

**Herramientas:**

- `SDV`: `CTGANSynthesizer`, `TVAESynthesizer`, `GaussianCopulaSynthesizer`
- `TabDDPM`: para evaluar modelo *SOTA*

---

## üîπ FASE 3 ‚Äî Evaluaci√≥n de calidad de los datos sint√©ticos

**Objetivos:**

- Comparar realismo, utilidad y preservaci√≥n de estructuras estad√≠sticas.

**M√©tricas a utilizar:**

- **Realismo estad√≠stico**
  - Divergencia de Jensen-Shannon (JS)
  - Kolmogorov-Smirnov (KS test por variable)
  - Histogramas y correlaciones cruzadas

- **Preservaci√≥n de correlaciones**
  - Pearson/Spearman
  - Matriz de correlaci√≥n real vs sint√©tica

- **Utilidad para ML**
  - Experimento TSTR (*Train on Synthetic, Test on Real*)
  - Comparar AUC, *accuracy*, F1 entre entrenamientos con datos reales y sint√©ticos

- **Privacidad (si aplica)**
  - *Nearest-neighbor overlap*
  - *Membership inference* (si se requiere robustez de privacidad)

**Herramientas:**

- `SDMetrics`
- `sklearn.metrics`, `xgboost`
- `matplotlib`, `seaborn`

---

## üîπ FASE 4 ‚Äî Reporte y visualizaci√≥n

**Objetivos:**

- Documentar resultados comparativos.
- Justificar elecci√≥n del mejor modelo generador.
- Visualizar distribuci√≥n y resultados predictivos.

**Acciones:**

- Comparar visualmente las distribuciones reales vs sint√©ticas.
- Crear matriz resumen de m√©tricas por modelo.
- Redactar informe con conclusiones robustas: realismo, utilidad y viabilidad.

---

# Instrucciones para rodar la aplicaci√≥n

1. Primero crea un ambiente virtual, puedes usar el nombre que quieras:  
   ```bash python -m venv venv```

2. Despu√©s activa el ambiente virtual:
   ```source venv/bin/activate```
    Para Windows haz:
    
    `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process`
    `.\venv\Scripts\Activate.ps1`

3. Con el ambiente virtual activado, instala las librer√≠as:
```pip install -r requirements.txt```

